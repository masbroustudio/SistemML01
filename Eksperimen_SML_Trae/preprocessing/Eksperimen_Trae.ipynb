{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_dataset",
   "metadata": {},
   "source": [
    "# **1. Perkenalan Dataset**\n",
    "Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagai berikut:\n",
    "\n",
    "**Sumber Dataset**:\n",
    "Dataset ini adalah dataset Titanic yang diperoleh dari Kaggle (atau public repository lainnya). Dataset ini digunakan untuk memprediksi apakah seorang penumpang selamat atau tidak berdasarkan fitur-fitur seperti kelas tiket, jenis kelamin, usia, dan lainnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import_library_md",
   "metadata": {},
   "source": [
    "# **2. Import Library**\n",
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_library_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_dataset_md",
   "metadata": {},
   "source": [
    "# **3. Memuat Dataset**\n",
    "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_dataset_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat dataset\n",
    "df = pd.read_csv('../titanic_raw/train.csv')\n",
    "\n",
    "# Menampilkan 5 baris pertama\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda_md",
   "metadata": {},
   "source": [
    "# **4. Exploratory Data Analysis (EDA)**\n",
    "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.\n",
    "\n",
    "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melihat informasi dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_describe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik deskriptif\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_isnull",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi distribusi target (Survived)\n",
    "sns.countplot(x='Survived', data=df)\n",
    "plt.title('Distribution of Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing_md",
   "metadata": {},
   "source": [
    "# **5. Data Preprocessing**\n",
    "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.\n",
    "\n",
    "Berikut adalah tahapan-tahapan yang bisa dilakukan, tetapi **tidak terbatas** pada:\n",
    "1. Menghapus atau Menangani Data Kosong (Missing Values)\n",
    "2. Menghapus Data Duplikat\n",
    "3. Normalisasi atau Standarisasi Fitur\n",
    "4. Deteksi dan Penanganan Outlier\n",
    "5. Encoding Data Kategorikal\n",
    "6. Binning (Pengelompokan Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep_drop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus kolom yang tidak diperlukan\n",
    "df_clean = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep_fillna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "# Age: isi dengan median\n",
    "df_clean['Age'] = df_clean['Age'].fillna(df_clean['Age'].median())\n",
    "\n",
    "# Embarked: isi dengan modus\n",
    "mode_embarked = df_clean['Embarked'].mode()[0]\n",
    "df_clean['Embarked'] = df_clean['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "# Cek kembali missing values\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep_encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Variables\n",
    "# Sex: Label Encoding (male=0, female=1)\n",
    "if 'Sex' in df_clean.columns:\n",
    "    df_clean['Sex'] = df_clean['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Embarked: One-Hot Encoding\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep_save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan data hasil preprocessing\n",
    "df_clean.to_csv('train_processed.csv', index=False)\n",
    "print(\"Data preprocessing selesai dan disimpan ke train_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
